{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.libs.models.simple_bot import MLChitChat\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_li = []\n",
    "with open('data/dialogues.txt') as f:\n",
    "    tmp_str = ''\n",
    "    for line in f.readlines():\n",
    "        if line == '\\n':\n",
    "            train_li.append(tmp_str)\n",
    "            tmp_str = ''\n",
    "        else:\n",
    "            tmp_str += line.strip('-').strip() + '<eom>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Пока, толстуха!&lt;eom&gt;Пока, малышка!&lt;eom&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Этому надо положить конец,&lt;eom&gt;Это не жизнь!&lt;eom&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>А ты не помолчишь?&lt;eom&gt;Замолчу, когда захочу.&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>А ты не помолчишь?&lt;eom&gt;Замолчу, когда захочу.&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Это зависит!&lt;eom&gt;Будет сегодня хорошая погода,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034001</th>\n",
       "      <td>Вот. Выпей. Тебе станет легче. Нет, нет, пока ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034002</th>\n",
       "      <td>Но почему ты спрашиваешь меня? Я думала, что.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034003</th>\n",
       "      <td>Никак потерял что?&lt;eom&gt;Да вот сокровище пропал...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034004</th>\n",
       "      <td>Ты что же, собирался убить ее?&lt;eom&gt;Разумеется....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034005</th>\n",
       "      <td>Ты что же, собирался убить ее?&lt;eom&gt;Разумеется....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1034006 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  dialogue\n",
       "0                  Пока, толстуха!<eom>Пока, малышка!<eom>\n",
       "1        Этому надо положить конец,<eom>Это не жизнь!<eom>\n",
       "2        А ты не помолчишь?<eom>Замолчу, когда захочу.<...\n",
       "3        А ты не помолчишь?<eom>Замолчу, когда захочу.<...\n",
       "4        Это зависит!<eom>Будет сегодня хорошая погода,...\n",
       "...                                                    ...\n",
       "1034001  Вот. Выпей. Тебе станет легче. Нет, нет, пока ...\n",
       "1034002  Но почему ты спрашиваешь меня? Я думала, что.....\n",
       "1034003  Никак потерял что?<eom>Да вот сокровище пропал...\n",
       "1034004  Ты что же, собирался убить ее?<eom>Разумеется....\n",
       "1034005  Ты что же, собирался убить ее?<eom>Разумеется....\n",
       "\n",
       "[1034006 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['dialogue'] = train_li\n",
    "del train_li\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<span class=participant_2>Пользователь 2: Привет) расскажи о себе</span><br /><span class=participant_1>Пользователь 1: Привет) под вкусный кофеек настроение поболтать появилось<br />)</span><br /><span class=participant_2>Пользователь 2: Что читаешь? Мне нравится классика</span><br /><span class=participant_2>Пользователь 2: Я тоже люблю пообщаться</span><br /><span class=participant_1>Пользователь 1: Люблю животных, просто обожаю, как и свою работу)</span><br /><span class=participant_1>Пользователь 1: Я фантастику люблю</span><br /><span class=participant_2>Пользователь 2: А я выращиваю фиалки</span><br /><span class=participant_2>Пользователь 2: И веду здоровый и активный образ жизни!</span><br /><span class=participant_1>Пользователь 1: Ух ты, интересно.</span><br /><span class=participant_2>Пользователь 2: Ты случайно не принц на белом коне? Я его очень жду<br />..</span><br /><span class=participant_1>Пользователь 1: А у меня из хобби каждую неделю тусить с моим лучшим<br />другом)</span><br />'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats = pd.read_csv('data/dialogues.tsv', sep='\\t')\n",
    "chats.loc[0, 'dialogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_char(text):\n",
    "    text = text.split('</span><br />')\n",
    "    prev_class = 0\n",
    "    cur_class = 0\n",
    "    new_dial = []\n",
    "    for t in text[:-1]:\n",
    "        t = t.replace('<br />', ' ')\n",
    "        if t.find('participant_1') > -1:\n",
    "            cur_class = 1\n",
    "        else:\n",
    "            cur_class = 2\n",
    "        t = t.replace('<span class=participant_1>', '').replace('<span class=participant_2>', '').replace('Пользователь 2: ', '').replace('Пользователь 1: ', '')\n",
    "        if cur_class == prev_class:\n",
    "            new_dial[-1] += '\\n' + t\n",
    "            prev_class = cur_class\n",
    "        else:\n",
    "            new_dial.append(t)\n",
    "            prev_class = cur_class\n",
    "\n",
    "    return '<eom>'.join(s for s in new_dial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Привет) расскажи о себе<eom>Привет) под вкусный кофеек настроение поболтать появилось )<eom>Что читаешь? Мне нравится классика\\nЯ тоже люблю пообщаться<eom>Люблю животных, просто обожаю, как и свою работу)\\nЯ фантастику люблю<eom>А я выращиваю фиалки\\nИ веду здоровый и активный образ жизни!<eom>Ух ты, интересно.<eom>Ты случайно не принц на белом коне? Я его очень жду ..<eom>А у меня из хобби каждую неделю тусить с моим лучшим другом)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '<span class=participant_2>Пользователь 2: Привет) расскажи о себе</span><br /><span class=participant_1>Пользователь 1: Привет) под вкусный кофеек настроение поболтать появилось<br />)</span><br /><span class=participant_2>Пользователь 2: Что читаешь? Мне нравится классика</span><br /><span class=participant_2>Пользователь 2: Я тоже люблю пообщаться</span><br /><span class=participant_1>Пользователь 1: Люблю животных, просто обожаю, как и свою работу)</span><br /><span class=participant_1>Пользователь 1: Я фантастику люблю</span><br /><span class=participant_2>Пользователь 2: А я выращиваю фиалки</span><br /><span class=participant_2>Пользователь 2: И веду здоровый и активный образ жизни!</span><br /><span class=participant_1>Пользователь 1: Ух ты, интересно.</span><br /><span class=participant_2>Пользователь 2: Ты случайно не принц на белом коне? Я его очень жду<br />..</span><br /><span class=participant_1>Пользователь 1: А у меня из хобби каждую неделю тусить с моим лучшим<br />другом)</span><br />'\n",
    "clear_char(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Привет) расскажи о себе<eom>Привет) под вкусный кофеек настроение поболтать появилось )<eom>Что читаешь? Мне нравится классика\\nЯ тоже люблю пообщаться<eom>Люблю животных, просто обожаю, как и свою работу)\\nЯ фантастику люблю<eom>А я выращиваю фиалки\\nИ веду здоровый и активный образ жизни!<eom>Ух ты, интересно.<eom>Ты случайно не принц на белом коне? Я его очень жду ..<eom>А у меня из хобби каждую неделю тусить с моим лучшим другом)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats['dialogue'] = chats['dialogue'].apply(clear_char)\n",
    "chats.loc[0, 'dialogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats['length'] = chats['dialogue'].apply(lambda x: len(x.split('<eom>')))\n",
    "train['length'] = train['dialogue'].apply(lambda x: len(x.split('<eom>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.loc[(train.length < 10) & (train.length > 2), 'length'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chats.loc[(chats.length < 10) & (chats.length > 2), 'length'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980564\n",
      "1290\n"
     ]
    }
   ],
   "source": [
    "print(train[(train.length < 7) & (train.length > 2)].shape[0])\n",
    "print(chats[(chats.length < 10) & (chats.length > 2)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10013\n",
      "20026\n",
      "30039\n",
      "40052\n"
     ]
    }
   ],
   "source": [
    "chats_li = chats['dialogue'].apply(lambda x: '<eom>'.join(s for s in x.split('<eom>')[:3]) + '<eom>').to_list()\n",
    "print(len(chats_li))\n",
    "chats_li.extend(chats['dialogue'].apply(lambda x: '<eom>'.join(s for s in x.split('<eom>')[3:6]) + '<eom>').to_list())\n",
    "print(len(chats_li))\n",
    "chats_li.extend(chats['dialogue'].apply(lambda x: '<eom>'.join(s for s in x.split('<eom>')[6:9]) + '<eom>').to_list())\n",
    "print(len(chats_li))\n",
    "chats_li.extend(chats['dialogue'].apply(lambda x: '<eom>'.join(s for s in x.split('<eom>')[9:12]) + '<eom>').to_list())\n",
    "print(len(chats_li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93494\n",
      "146936\n"
     ]
    }
   ],
   "source": [
    "chats_li.extend(train.loc[train.length > 6, 'dialogue'].apply(lambda x: '<eom>'.join(s for s in x.split('<eom>')[:3]) + '<eom>').to_list())\n",
    "print(len(chats_li))\n",
    "chats_li.extend(train.loc[train.length > 6, 'dialogue'].apply(lambda x: '<eom>'.join(s for s in x.split('<eom>')[3:6]) + '<eom>').to_list())\n",
    "print(len(chats_li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Люблю животных, просто обожаю, как и свою работу)\n",
      "Я фантастику люблю<eom>А я выращиваю фиалки\n",
      "И веду здоровый и активный образ жизни!<eom>Ух ты, интересно.<eom>\n",
      "Чего так дешево - украл, что ли?<eom>А ты прокурор?<eom>Сколько у тебя в сумке?<eom>\n"
     ]
    }
   ],
   "source": [
    "print(chats_li[10013])\n",
    "print(chats_li[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144687\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chats = pd.DataFrame()\n",
    "chats['dialogue'] = chats_li\n",
    "chats['length'] = chats['dialogue'].apply(lambda x: len(x.split('<eom>')[:-1]))\n",
    "chats = chats[chats.length > 1]\n",
    "print(chats.shape[0])\n",
    "print(chats.length.min())\n",
    "chats['length'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train[(train.length < 7) & (train.length > 2)].sample(820000)\n",
    "val_df = train[(train.length < 7) & (train.length > 2) & (~train.index.isin(train_df.index))]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = chats.sample(int(0.9*chats.shape[0]))\n",
    "val_df = chats[(~chats.index.isin(train_df.index))]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130218\n",
      "14469\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape[0])\n",
    "print(val_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Только что убили хозяина. Здесь в баре.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[0, 'dialogue'].split('<eom>')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['question'] = train_df['dialogue'].apply(lambda x: \"<eom>\".join(s for s in x.split('<eom>')[:-2]))\n",
    "train_df['answer'] = train_df['dialogue'].apply(lambda x: x.split('<eom>')[-2])\n",
    "val_df['question'] = val_df['dialogue'].apply(lambda x: \"<eom>\".join(s for s in x.split('<eom>')[:-2]))\n",
    "val_df['answer'] = val_df['dialogue'].apply(lambda x: x.split('<eom>')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>length</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Здравствуйте\\nЯ Леша&lt;eom&gt;Здравствуйте\\nЯ Егор&lt;...</td>\n",
       "      <td>3</td>\n",
       "      <td>Здравствуйте\\nЯ Леша&lt;eom&gt;Здравствуйте\\nЯ Егор</td>\n",
       "      <td>Я учусь в 6 классе</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Привет&lt;eom&gt;Привет&lt;eom&gt;Как дела? Я и Норвегии,а...</td>\n",
       "      <td>3</td>\n",
       "      <td>Привет&lt;eom&gt;Привет</td>\n",
       "      <td>Как дела? Я и Норвегии,а ты?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Привет. Как дела?&lt;eom&gt;Привет. У меня неочень. ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Привет. Как дела?&lt;eom&gt;Привет. У меня неочень. ...</td>\n",
       "      <td>Чем любишь заниматься? Я художник. Очень люблю...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Привет&lt;eom&gt;Давай знакомится?&lt;eom&gt;Давай&lt;eom&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>Привет&lt;eom&gt;Давай знакомится?</td>\n",
       "      <td>Давай</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>привет&lt;eom&gt;Приветик\\nКак дела?&lt;eom&gt;надеюсь не ...</td>\n",
       "      <td>3</td>\n",
       "      <td>привет&lt;eom&gt;Приветик\\nКак дела?</td>\n",
       "      <td>надеюсь не глупый у меня собеседник ?))))) отл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14464</th>\n",
       "      <td>И молодая.&lt;eom&gt;Правда?.. Я тебе верю. Верю, но...</td>\n",
       "      <td>3</td>\n",
       "      <td>И молодая.&lt;eom&gt;Правда?.. Я тебе верю. Верю, но...</td>\n",
       "      <td>Боишься? Но чего?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14465</th>\n",
       "      <td>Домой. Сейчас парни придут. А велик у тебя отк...</td>\n",
       "      <td>3</td>\n",
       "      <td>Домой. Сейчас парни придут. А велик у тебя отк...</td>\n",
       "      <td>На кой он мне? У меня же есть.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14466</th>\n",
       "      <td>Нет. Мне девятнадцать.&lt;eom&gt;Скоро суд?&lt;eom&gt;Скор...</td>\n",
       "      <td>3</td>\n",
       "      <td>Нет. Мне девятнадцать.&lt;eom&gt;Скоро суд?</td>\n",
       "      <td>Скоро.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14467</th>\n",
       "      <td>Ну, говори.&lt;eom&gt;Дай закурить?&lt;eom&gt;Я не курю.&lt;eom&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>Ну, говори.&lt;eom&gt;Дай закурить?</td>\n",
       "      <td>Я не курю.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14468</th>\n",
       "      <td>Да.&lt;eom&gt;В какой?&lt;eom&gt;В этой,&lt;eom&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>Да.&lt;eom&gt;В какой?</td>\n",
       "      <td>В этой,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14469 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                dialogue  length  \\\n",
       "0      Здравствуйте\\nЯ Леша<eom>Здравствуйте\\nЯ Егор<...       3   \n",
       "1      Привет<eom>Привет<eom>Как дела? Я и Норвегии,а...       3   \n",
       "2      Привет. Как дела?<eom>Привет. У меня неочень. ...       3   \n",
       "3            Привет<eom>Давай знакомится?<eom>Давай<eom>       3   \n",
       "4      привет<eom>Приветик\\nКак дела?<eom>надеюсь не ...       3   \n",
       "...                                                  ...     ...   \n",
       "14464  И молодая.<eom>Правда?.. Я тебе верю. Верю, но...       3   \n",
       "14465  Домой. Сейчас парни придут. А велик у тебя отк...       3   \n",
       "14466  Нет. Мне девятнадцать.<eom>Скоро суд?<eom>Скор...       3   \n",
       "14467  Ну, говори.<eom>Дай закурить?<eom>Я не курю.<eom>       3   \n",
       "14468                  Да.<eom>В какой?<eom>В этой,<eom>       3   \n",
       "\n",
       "                                                question  \\\n",
       "0          Здравствуйте\\nЯ Леша<eom>Здравствуйте\\nЯ Егор   \n",
       "1                                      Привет<eom>Привет   \n",
       "2      Привет. Как дела?<eom>Привет. У меня неочень. ...   \n",
       "3                           Привет<eom>Давай знакомится?   \n",
       "4                         привет<eom>Приветик\\nКак дела?   \n",
       "...                                                  ...   \n",
       "14464  И молодая.<eom>Правда?.. Я тебе верю. Верю, но...   \n",
       "14465  Домой. Сейчас парни придут. А велик у тебя отк...   \n",
       "14466              Нет. Мне девятнадцать.<eom>Скоро суд?   \n",
       "14467                      Ну, говори.<eom>Дай закурить?   \n",
       "14468                                   Да.<eom>В какой?   \n",
       "\n",
       "                                                  answer  \n",
       "0                                     Я учусь в 6 классе  \n",
       "1                           Как дела? Я и Норвегии,а ты?  \n",
       "2      Чем любишь заниматься? Я художник. Очень люблю...  \n",
       "3                                                  Давай  \n",
       "4      надеюсь не глупый у меня собеседник ?))))) отл...  \n",
       "...                                                  ...  \n",
       "14464                                  Боишься? Но чего?  \n",
       "14465                     На кой он мне? У меня же есть.  \n",
       "14466                                             Скоро.  \n",
       "14467                                         Я не курю.  \n",
       "14468                                            В этой,  \n",
       "\n",
       "[14469 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='cointegrated/rut5-small-chitchat', vocab_size=20200, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLChitChat()\n",
    "# additional_special_tokens = model.tokenizer.special_tokens_map['additional_special_tokens']\n",
    "model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200\n",
      "[20199, 1]\n",
      "[20100, 1]\n",
      "[1042, 265, 773, 669, 1]\n",
      "20200\n",
      "[20199, 1]\n",
      "[20100, 1]\n",
      "[20200, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<eom>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.tokenizer.vocab_size)\n",
    "print(model.tokenizer.encode(\"<extra_id_0>\"))\n",
    "print(model.tokenizer.encode(\"<extra_id_99>\"))\n",
    "print(model.tokenizer.encode(\"<eom>\"))\n",
    "model.tokenizer.add_special_tokens({'sep_token': \"<eom>\"})\n",
    "# model.tokenizer.additional_special_tokens = additional_special_tokens\n",
    "print(model.tokenizer.vocab_size)\n",
    "print(model.tokenizer.encode(\"<extra_id_0>\"))\n",
    "print(model.tokenizer.encode(\"<extra_id_99>\"))\n",
    "print(model.tokenizer.encode(\"<eom>\"))\n",
    "model.tokenizer.convert_ids_to_tokens(20200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20201"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(20201, 512)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generator.resize_token_embeddings(len(model.tokenizer.get_vocab()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(20201, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(20201, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(20201, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedGeluDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=20201, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет) расскажи о себе<eom>Привет) под вкусный кофеек настроение поболтать появилось )<eom>Что читаешь? Мне нравится классика\n",
      "Я тоже люблю пообщаться<eom>Люблю животных, просто обожаю, как и свою работу)\n",
      "Я фантастику люблю<eom>А я выращиваю фиалки\n",
      "И веду здоровый и активный образ жизни!<eom>Ух ты, интересно.<eom>Ты случайно не принц на белом коне? Я его очень жду ..<eom>А у меня из хобби каждую неделю тусить с моим лучшим другом)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Мне тоже нравится, я надеюсь, что он выращивает большие фиалки.',\n",
       "  -0.5089200735092163),\n",
       " ('я тоже люблю, но я думаю, что это очень хорошая работа. Я надеюсь, что все получится весело!',\n",
       "  -0.38615018129348755),\n",
       " ('Это здорово! У меня всё получится!!!', -0.9721251130104065)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clear_char(test))\n",
    "model(clear_char(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['За наши города!<eom>За наших женщин! За наших детей!'\n",
      " 'Княже! - кричал кто-то то сбоку, то сзади.']\n",
      "['Здравствуйте\\nЯ Леша<eom>Здравствуйте\\nЯ Егор' 'Я учусь в 6 классе']\n"
     ]
    }
   ],
   "source": [
    "pairs = train_df[['question', 'answer']].values\n",
    "print(pairs[0, :])\n",
    "val_pairs = val_df[['question', 'answer']].values\n",
    "print(val_pairs[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model.generator.cuda()\n",
    "optimizer = torch.optim.Adam(model.generator.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/65109 [00:00<2:03:18,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 3.115985631942749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1002/65109 [01:44<1:50:32,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000 loss 3.4471980141401293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2002/65109 [03:29<1:56:38,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2000 loss 3.3300618364810943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3002/65109 [05:13<1:47:01,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3000 loss 3.367481422960758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 4002/65109 [06:57<1:43:30,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4000 loss 3.3565290806889534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5002/65109 [08:39<1:40:46,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5000 loss 3.312300791025162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 6002/65109 [10:22<1:40:58,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6000 loss 3.314377509593964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 7002/65109 [12:05<1:39:30,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7000 loss 3.2687575657367707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 8002/65109 [13:48<1:37:39,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8000 loss 3.3104700867533685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 9002/65109 [15:30<1:36:19,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9000 loss 3.2798306809067728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 10002/65109 [17:13<1:33:41,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10000 loss 3.2702322623729705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 11002/65109 [18:56<1:33:02,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11000 loss 3.302186272919178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 12002/65109 [20:39<1:32:34,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12000 loss 3.2284191232323645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 13002/65109 [22:21<1:28:43,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 13000 loss 3.2782638363838195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 14002/65109 [24:04<1:26:22,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 14000 loss 3.2022857100963593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 15002/65109 [25:45<1:25:20,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15000 loss 3.25102147680521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 16002/65109 [27:28<1:24:21,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16000 loss 3.2281905057430267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 17003/65109 [29:11<1:22:16,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 17000 loss 3.2553275725245476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 18002/65109 [30:54<1:21:53,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18000 loss 3.2159819596111774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 19003/65109 [32:37<1:16:09, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19000 loss 3.1954768838882446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 20002/65109 [34:20<1:17:27,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20000 loss 3.201230773746967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 21002/65109 [36:02<1:15:05,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 21000 loss 3.2063955262899397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 22002/65109 [37:45<1:15:21,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 22000 loss 3.187382999539375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 23002/65109 [39:27<1:11:55,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 23000 loss 3.207258241891861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 24002/65109 [41:10<1:10:43,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 24000 loss 3.2361978863477705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 25002/65109 [42:52<1:08:41,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 25000 loss 3.228820106983185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 26002/65109 [44:37<1:08:16,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 26000 loss 3.199788388252258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 27002/65109 [46:22<1:06:26,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 27000 loss 3.2197263151407243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 28002/65109 [48:07<1:05:02,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 28000 loss 3.2296208064556122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 29002/65109 [49:51<1:03:17,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 29000 loss 3.169963461458683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 30002/65109 [51:36<59:09,  9.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30000 loss 3.221647854745388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 31002/65109 [53:20<1:00:10,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 31000 loss 3.1876428775191306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 32002/65109 [55:03<56:13,  9.81it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 32000 loss 3.2241081143915653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 33002/65109 [56:47<55:16,  9.68it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 33000 loss 3.171362874507904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 34002/65109 [58:32<54:15,  9.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 34000 loss 3.163117436826229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 35002/65109 [1:00:17<52:19,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 35000 loss 3.2279421983957293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 36002/65109 [1:02:02<50:48,  9.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 36000 loss 3.189330155789852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 37002/65109 [1:03:48<48:58,  9.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 37000 loss 3.1877514412403105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 38002/65109 [1:05:32<46:55,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 38000 loss 3.153031407058239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 39002/65109 [1:07:16<45:49,  9.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 39000 loss 3.1825489787459373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 40002/65109 [1:09:00<43:06,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40000 loss 3.148696177959442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 41002/65109 [1:10:45<42:41,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 41000 loss 3.1501326568722723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 42002/65109 [1:12:29<40:31,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 42000 loss 3.1884008872509004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 43002/65109 [1:14:15<38:09,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 43000 loss 3.1432268384695052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 44002/65109 [1:16:00<36:34,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 44000 loss 3.170170340538025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 45002/65109 [1:17:45<34:17,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 45000 loss 3.203141771018505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 46002/65109 [1:19:29<32:30,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 46000 loss 3.1835180445313456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 47002/65109 [1:21:14<31:00,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 47000 loss 3.133787579059601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 48002/65109 [1:22:58<29:43,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 48000 loss 3.1736172177791597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 49002/65109 [1:24:42<29:02,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49000 loss 3.148015084862709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 50002/65109 [1:26:27<26:29,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50000 loss 3.1614753194451333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 51002/65109 [1:28:12<24:35,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 51000 loss 3.12683158403635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 52002/65109 [1:29:57<22:24,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 52000 loss 3.1735910010933877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 53002/65109 [1:31:42<20:52,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 53000 loss 3.197618998557329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 54002/65109 [1:33:28<19:17,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 54000 loss 3.1409060355424883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 55002/65109 [1:35:13<17:37,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 55000 loss 3.156679032146931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 56002/65109 [1:36:57<15:39,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 56000 loss 3.1261500188708307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 57002/65109 [1:38:42<14:08,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 57000 loss 3.177689130485058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 58002/65109 [1:40:27<12:38,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 58000 loss 3.0638647976815703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 59002/65109 [1:42:12<10:40,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 59000 loss 3.1698557267189025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 60002/65109 [1:43:58<09:28,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60000 loss 3.172553011536598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 61002/65109 [1:45:43<07:11,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 61000 loss 3.1396613978743555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 62002/65109 [1:47:29<05:39,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 62000 loss 3.1691228169202805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 63002/65109 [1:49:14<03:37,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 63000 loss 3.147324693918228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 64002/65109 [1:50:59<01:56,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 64000 loss 3.12085104739666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 65002/65109 [1:52:44<00:11,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 65000 loss 3.126896648198366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65109/65109 [1:52:55<00:00,  9.61it/s]\n",
      "100%|██████████| 7234/7234 [02:28<00:00, 48.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 val loss 3.0515635019430376\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/65109 [00:00<1:56:22,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 3.1230856958925726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1003/65109 [01:45<1:48:45,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000 loss 2.9371050597429273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2002/65109 [03:31<1:49:05,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2000 loss 2.8904210361242293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3002/65109 [05:16<1:46:24,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3000 loss 2.9281986298561096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 4002/65109 [07:02<1:46:27,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4000 loss 2.962990611732006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5002/65109 [08:47<1:44:58,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5000 loss 2.9116674496531485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 6003/65109 [10:32<1:40:14,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6000 loss 2.9328700610995293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 7002/65109 [12:17<1:37:57,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7000 loss 2.9382197051942347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 8002/65109 [14:02<1:43:39,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8000 loss 2.969256497502327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 9002/65109 [15:48<1:37:10,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9000 loss 2.984913246154785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 10002/65109 [17:33<1:36:19,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10000 loss 3.004343357264996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 11002/65109 [19:19<1:35:50,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11000 loss 2.935414650440216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 12002/65109 [21:04<1:34:45,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12000 loss 3.0026145140528677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 13002/65109 [22:50<1:30:35,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 13000 loss 2.9368073893785476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 14002/65109 [24:35<1:30:14,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 14000 loss 2.95196058511734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 15002/65109 [26:21<1:25:05,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15000 loss 2.973482268035412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 16002/65109 [28:06<1:28:35,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16000 loss 2.998954639613628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 17002/65109 [29:52<1:23:12,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 17000 loss 2.9640813958644867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 18002/65109 [31:38<1:21:56,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18000 loss 2.956559029877186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 19002/65109 [33:24<1:19:55,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19000 loss 2.9700331729650498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 20002/65109 [35:09<1:17:06,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20000 loss 2.9897962781190874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 21002/65109 [36:54<1:15:36,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 21000 loss 3.0033632670640946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 22002/65109 [38:39<1:20:55,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 22000 loss 2.9875424259305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 23002/65109 [40:25<1:13:16,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 23000 loss 2.9639522297978402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 24002/65109 [42:10<1:12:26,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 24000 loss 2.9594268282055856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 25002/65109 [43:56<1:11:23,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 25000 loss 2.9653061034083366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 26002/65109 [45:41<1:07:34,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 26000 loss 2.952152203798294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 27002/65109 [47:26<1:05:47,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 27000 loss 2.996684437811375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 28002/65109 [49:12<1:04:53,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 28000 loss 3.032927464514971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 29002/65109 [50:58<1:03:44,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 29000 loss 3.001095896959305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 30002/65109 [52:43<1:00:55,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30000 loss 2.9523895555138586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 31002/65109 [54:29<1:01:16,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 31000 loss 3.001489722430706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 32002/65109 [56:14<58:38,  9.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 32000 loss 2.9527502346038816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 33002/65109 [58:00<56:23,  9.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 33000 loss 3.027418900489807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 34002/65109 [59:45<53:22,  9.71it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 34000 loss 3.003920169889927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 35002/65109 [1:01:31<54:50,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 35000 loss 2.9990100528597834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 36002/65109 [1:03:17<1:00:13,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 36000 loss 2.9617171778678895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 37002/65109 [1:05:02<47:41,  9.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 37000 loss 2.97913768607378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 38002/65109 [1:06:47<46:57,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 38000 loss 2.9956906884908676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 39002/65109 [1:08:33<45:22,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 39000 loss 3.0241630551218988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 40002/65109 [1:10:19<47:10,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40000 loss 2.9863451470732687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 41002/65109 [1:12:05<45:05,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 41000 loss 2.982188836157322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 42002/65109 [1:13:50<42:06,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 42000 loss 3.003353554546833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 43002/65109 [1:15:36<40:22,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 43000 loss 2.9530670024752617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 44002/65109 [1:17:22<38:06,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 44000 loss 3.0180839532613755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 45002/65109 [1:19:08<34:31,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 45000 loss 2.962843077301979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 46002/65109 [1:20:54<34:15,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 46000 loss 3.0070746031403544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 47002/65109 [1:22:39<32:08,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 47000 loss 2.9805157074928283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 48002/65109 [1:24:25<29:17,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 48000 loss 2.985894159913063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 49002/65109 [1:26:11<27:52,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49000 loss 3.0325248118042945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 50002/65109 [1:27:56<25:54,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50000 loss 2.9862916840910914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 51002/65109 [1:29:42<24:35,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 51000 loss 2.9303329979777337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 52002/65109 [1:31:28<23:08,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 52000 loss 2.9926504199504853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 53002/65109 [1:33:14<20:47,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 53000 loss 3.0134385135173796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 54002/65109 [1:35:00<19:51,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 54000 loss 3.0063988787531852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 55002/65109 [1:36:46<17:45,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 55000 loss 2.9944640634059905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 56002/65109 [1:38:31<16:05,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 56000 loss 2.994293962776661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 57002/65109 [1:40:17<14:20,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 57000 loss 3.0083735522031785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 58002/65109 [1:42:02<13:10,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 58000 loss 2.9952574739456175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 59002/65109 [1:43:47<10:55,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 59000 loss 2.9699328010082247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 60002/65109 [1:45:33<08:53,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60000 loss 3.039139915943146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 61002/65109 [1:47:19<07:10,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 61000 loss 3.0429152058362963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 62002/65109 [1:49:05<05:35,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 62000 loss 2.996958570420742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 63002/65109 [1:50:50<03:35,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 63000 loss 2.998054274722934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 64002/65109 [1:52:36<01:55,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 64000 loss 2.9735895517766475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 65002/65109 [1:54:22<00:11,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 65000 loss 2.980310603737831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65109/65109 [1:54:33<00:00,  9.47it/s]\n",
      "100%|██████████| 7234/7234 [02:28<00:00, 48.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 val loss 2.660915057291502\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/65109 [00:00<1:53:22,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 2.9895624039173128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1002/65109 [01:45<1:53:52,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000 loss 2.271717524558306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2002/65109 [03:30<1:50:23,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2000 loss 2.298163989290595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 3002/65109 [05:15<1:50:14,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3000 loss 2.3237935988307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 4002/65109 [07:01<1:44:38,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4000 loss 2.3367138966619967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5002/65109 [08:47<1:48:19,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5000 loss 2.3792200812101365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 6002/65109 [10:33<1:43:06,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6000 loss 2.3950785069465637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 7002/65109 [12:18<1:40:05,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7000 loss 2.375343783378601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 8002/65109 [14:04<1:39:08,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8000 loss 2.4139577558338643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 9002/65109 [15:49<1:38:02,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9000 loss 2.45748311072588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 10002/65109 [17:35<1:35:05,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10000 loss 2.477379166871309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 11002/65109 [19:20<1:33:18,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11000 loss 2.5096372020989657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 12002/65109 [21:05<1:31:27,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12000 loss 2.482928865790367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 13002/65109 [22:51<1:30:20,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 13000 loss 2.6004069682955744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 14002/65109 [24:36<1:30:15,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 14000 loss 2.5099179078936578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 15002/65109 [26:22<1:26:22,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15000 loss 2.5322947320342064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 16002/65109 [28:08<1:26:41,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16000 loss 2.5372208180725573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 17002/65109 [29:54<1:24:02,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 17000 loss 2.516872252672911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 18002/65109 [31:40<1:21:00,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18000 loss 2.5578200941979885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 19002/65109 [33:25<1:19:18,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19000 loss 2.5276321724802258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 20002/65109 [35:11<1:17:12,  9.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20000 loss 2.579323800086975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 21002/65109 [36:57<1:19:47,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 21000 loss 2.584570235833526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 22002/65109 [38:43<1:15:44,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 22000 loss 2.603358153283596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 23002/65109 [40:29<1:12:42,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 23000 loss 2.555887458562851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 24002/65109 [42:15<1:12:38,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 24000 loss 2.5964201566874983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 25002/65109 [44:01<1:11:35,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 25000 loss 2.6028941169679163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 26002/65109 [45:47<1:09:40,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 26000 loss 2.599065214455128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 27002/65109 [47:33<1:05:21,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 27000 loss 2.5869082901775835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 28002/65109 [49:19<1:04:21,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 28000 loss 2.6076432774960994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 29002/65109 [51:05<1:02:30,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 29000 loss 2.6089356160759927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 30002/65109 [52:51<1:03:45,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30000 loss 2.6277197425961494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 31002/65109 [54:37<59:57,  9.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 31000 loss 2.595476186811924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 32002/65109 [56:23<57:57,  9.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 32000 loss 2.6369694160223007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 33002/65109 [58:09<56:01,  9.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 33000 loss 2.5883445373773575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 34002/65109 [59:55<53:43,  9.65it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 34000 loss 2.600948031127453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 35002/65109 [1:01:41<51:48,  9.69it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 35000 loss 2.6225170931220054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 36002/65109 [1:03:27<52:30,  9.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 36000 loss 2.6541262559294703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 37002/65109 [1:05:13<49:09,  9.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 37000 loss 2.6588121801018714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 38002/65109 [1:06:59<47:13,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 38000 loss 2.6733043503165246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 39002/65109 [1:08:45<45:44,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 39000 loss 2.6343851767778395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 40002/65109 [1:10:31<43:55,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40000 loss 2.6695010421276093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 41002/65109 [1:12:16<41:24,  9.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 41000 loss 2.635946304768324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 42002/65109 [1:14:02<39:46,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 42000 loss 2.6599662283957004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 43002/65109 [1:15:49<38:55,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 43000 loss 2.6260095534920693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 44002/65109 [1:17:34<37:38,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 44000 loss 2.6358492608964443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 45002/65109 [1:19:20<34:38,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 45000 loss 2.679234645485878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 46002/65109 [1:21:06<33:11,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 46000 loss 2.6863336951434613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 47002/65109 [1:22:52<32:28,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 47000 loss 2.700242034688592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 48002/65109 [1:24:37<29:42,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 48000 loss 2.674192544579506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 49002/65109 [1:26:23<29:13,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49000 loss 2.7079758969843386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 50002/65109 [1:28:10<26:36,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50000 loss 2.6758830653429033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 51002/65109 [1:29:56<24:46,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 51000 loss 2.667062285542488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 52002/65109 [1:31:42<23:28,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 52000 loss 2.705659600108862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 53002/65109 [1:33:27<20:57,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 53000 loss 2.716654321372509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 54002/65109 [1:35:13<18:57,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 54000 loss 2.6787548153996465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 55002/65109 [1:36:59<17:39,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 55000 loss 2.6911991748809814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 56002/65109 [1:38:45<16:03,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 56000 loss 2.705561098098755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 57002/65109 [1:40:30<14:34,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 57000 loss 2.6603520337343216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 58002/65109 [1:42:16<12:40,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 58000 loss 2.71131375682354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 59002/65109 [1:44:03<10:33,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 59000 loss 2.6997887679040433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 60002/65109 [1:45:49<08:59,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60000 loss 2.7075126571059225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 61002/65109 [1:47:34<07:14,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 61000 loss 2.726944171100855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 62002/65109 [1:49:20<05:28,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 62000 loss 2.7002613496780397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 63002/65109 [1:51:06<03:35,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 63000 loss 2.692609035536647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 64002/65109 [1:52:52<02:00,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 64000 loss 2.695882268399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 65002/65109 [1:54:38<00:11,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 65000 loss 2.725517353117466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65109/65109 [1:54:49<00:00,  9.45it/s]\n",
      "100%|██████████| 7234/7234 [02:30<00:00, 48.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 val loss 1.8726497669476385\n",
      "[3.0515635019430376, 2.660915057291502, 1.8726497669476385]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import trange\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 2  # сколько примеров показываем модели за один шаг\n",
    "report_steps = 1000  # раз в сколько шагов печатаем результат\n",
    "epochs = 3  # сколько раз мы покажем данные модели\n",
    "\n",
    "model.generator.train()\n",
    "losses = []\n",
    "epoch_losses = []\n",
    "for epoch in range(epochs):\n",
    "    print('EPOCH', epoch)\n",
    "    random.shuffle(pairs)\n",
    "    for i in trange(0, int(len(pairs) / batch_size)):\n",
    "        batch = pairs[i * batch_size: (i + 1) * batch_size]\n",
    "        # кодируем вопрос и ответ \n",
    "        x = model.tokenizer([p[0] for p in batch], return_tensors='pt', padding=True).to(model.generator.device)\n",
    "        y = model.tokenizer([p[1] for p in batch], return_tensors='pt', padding=True).to(model.generator.device)\n",
    "        # -100 - специальное значение, позволяющее не учитывать токены\n",
    "        y.input_ids[y.input_ids == 0] = -100\n",
    "        # вычисляем функцию потерь\n",
    "        loss = model.generator(\n",
    "            input_ids=x.input_ids,\n",
    "            attention_mask=x.attention_mask,\n",
    "            labels=y.input_ids,\n",
    "            decoder_attention_mask=y.attention_mask,\n",
    "            return_dict=True\n",
    "        ).loss\n",
    "        # делаем шаг градиентного спуска\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # печатаем скользящее среднее значение функции потерь\n",
    "        losses.append(loss.item())\n",
    "        if i % report_steps == 0:\n",
    "            print('step', i, 'loss', np.mean(losses[-report_steps:]))\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for i in trange(0, int(len(val_pairs) / batch_size)):\n",
    "            batch = pairs[i * batch_size: (i + 1) * batch_size]\n",
    "            # кодируем вопрос и ответ \n",
    "            x = model.tokenizer([p[0] for p in batch], return_tensors='pt', padding=True).to(model.generator.device)\n",
    "            y = model.tokenizer([p[1] for p in batch], return_tensors='pt', padding=True).to(model.generator.device)\n",
    "            # -100 - специальное значение, позволяющее не учитывать токены\n",
    "            y.input_ids[y.input_ids == 0] = -100\n",
    "            # вычисляем функцию потерь\n",
    "            loss = model.generator(\n",
    "                input_ids=x.input_ids,\n",
    "                attention_mask=x.attention_mask,\n",
    "                labels=y.input_ids,\n",
    "                decoder_attention_mask=y.attention_mask,\n",
    "                return_dict=True\n",
    "            ).loss\n",
    "            # печатаем скользящее среднее значение функции потерь\n",
    "            val_losses.append(loss.item())\n",
    "    \n",
    "    val_losses = np.mean(val_losses)\n",
    "    print('epoch', epoch, 'val loss', val_losses)\n",
    "    epoch_losses.append(val_losses)\n",
    "\n",
    "print(epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет) расскажи о себе<eom>Привет) под вкусный кофеек настроение поболтать появилось )<eom>Что читаешь? Мне нравится классика\n",
      "Я тоже люблю пообщаться<eom>Люблю животных, просто обожаю, как и свою работу)\n",
      "Я фантастику люблю<eom>А я выращиваю фиалки\n",
      "И веду здоровый и активный образ жизни!<eom>Ух ты, интересно.<eom>Ты случайно не принц на белом коне? Я его очень жду ..<eom>А у меня из хобби каждую неделю тусить с моим лучшим другом)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Я тоже не люблю животных, а у тебя есть семья?', -0.2920151650905609),\n",
       " ('Да, я не люблю кошек, но ведь у меня есть собака', -0.6903454065322876),\n",
       " ('Это круто) А у тебя есть семья?', -0.4034108817577362)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generator.eval()\n",
    "model.generator.cpu()\n",
    "print(clear_char(test))\n",
    "model(clear_char(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С каждого?<eom>С каждого.<eom>И вас четверо?<eom>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Что?', -0.8778696656227112),\n",
       " ('И вас кто-нибудь спрашивает?', -0.595618486404419),\n",
       " ('Это ваша милость.', -0.8308753371238708)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = chats['dialogue'].sample().values[0]\n",
    "print(text)\n",
    "model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generator.save_pretrained('.resource/model_data/generator/v1.2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('.resource/model_data/tokenizer/tokenizer_config.json',\n",
       " '.resource/model_data/tokenizer/special_tokens_map.json',\n",
       " '.resource/model_data/tokenizer/spiece.model',\n",
       " '.resource/model_data/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.save_pretrained('.resource/model_data/tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import trange\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/satellite/Documents/python_workdir/python_projects/guildenstern/finetuning.ipynb Cell 39'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/satellite/Documents/python_workdir/python_projects/guildenstern/finetuning.ipynb#ch0000037?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m MLChitChat()\n",
      "File \u001b[0;32m~/Documents/python_workdir/python_projects/guildenstern/src/libs/models/simple_bot.py:14\u001b[0m, in \u001b[0;36mMLChitChat.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/src/libs/models/simple_bot.py?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/src/libs/models/simple_bot.py?line=13'>14</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m T5Tokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mcointegrated/rut5-small-chitchat\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/src/libs/models/simple_bot.py?line=14'>15</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator \u001b[39m=\u001b[39m T5ForConditionalGeneration\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mcointegrated/rut5-small-chitchat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/src/libs/models/simple_bot.py?line=15'>16</a>\u001b[0m     config_path \u001b[39m=\u001b[39m os_path\u001b[39m.\u001b[39mabspath(os_path\u001b[39m.\u001b[39mjoin(os_path\u001b[39m.\u001b[39mdirname(\u001b[39m__file__\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mbot_config.yml\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1707\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1704'>1705</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1705'>1706</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1706'>1707</a>\u001b[0m         resolved_vocab_files[file_id] \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1707'>1708</a>\u001b[0m             file_path,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1708'>1709</a>\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1709'>1710</a>\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1710'>1711</a>\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1711'>1712</a>\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1712'>1713</a>\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1713'>1714</a>\u001b[0m             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1714'>1715</a>\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1715'>1716</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1717'>1718</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py?line=1718'>1719</a>\u001b[0m         \u001b[39mif\u001b[39;00m local_files_only:\n",
      "File \u001b[0;32m~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py:1846\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1841'>1842</a>\u001b[0m     local_files_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1843'>1844</a>\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1844'>1845</a>\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m-> <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1845'>1846</a>\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1846'>1847</a>\u001b[0m         url_or_filename,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1847'>1848</a>\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1848'>1849</a>\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1849'>1850</a>\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1850'>1851</a>\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1851'>1852</a>\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1852'>1853</a>\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1853'>1854</a>\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1854'>1855</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1855'>1856</a>\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1856'>1857</a>\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=1857'>1858</a>\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py:2102\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2095'>2096</a>\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2096'>2097</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mCannot find the requested files in the cached path and outgoing traffic has been\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2097'>2098</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m disabled. To enable model look-ups and downloads online, set \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlocal_files_only\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2098'>2099</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m to False.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2099'>2100</a>\u001b[0m                 )\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2100'>2101</a>\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2101'>2102</a>\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2102'>2103</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mConnection error, and we cannot find the requested files in the cached path.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2103'>2104</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m Please try again or make sure your Internet connection is on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2104'>2105</a>\u001b[0m                 )\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2106'>2107</a>\u001b[0m \u001b[39m# From now on, etag is not None.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/Documents/python_workdir/python_projects/guildenstern/.env/lib/python3.8/site-packages/transformers/file_utils.py?line=2107'>2108</a>\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(cache_path) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m force_download:\n",
      "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "model = MLChitChat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model.tokenizer = T5Tokenizer.from_pretrained('.resource/model_data/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generator = T5ForConditionalGeneration.from_pretrained('.resource/model_data/generator/v1.1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generator = T5ForConditionalGeneration.from_pretrained('.resource/model_data/generator/v1.2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3617/3617 [01:59<00:00, 30.30it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "perp = []\n",
    "model.generator.cuda()\n",
    "with torch.no_grad():\n",
    "    for i in trange(0, int(len(val_pairs) / batch_size)):\n",
    "        batch = pairs[i * batch_size: (i + 1) * batch_size]\n",
    "        # кодируем вопрос и ответ \n",
    "        x = model.tokenizer([p[0] for p in batch], return_tensors='pt', padding=True).to(model.generator.device)\n",
    "        y = model.tokenizer([p[1] for p in batch], return_tensors='pt', padding=True).to(model.generator.device)\n",
    "        # -100 - специальное значение, позволяющее не учитывать токены\n",
    "        y.input_ids[y.input_ids == 0] = -100\n",
    "        # вычисляем функцию потерь\n",
    "        loss = model.generator(\n",
    "            input_ids=x.input_ids,\n",
    "            attention_mask=x.attention_mask,\n",
    "            labels=y.input_ids,\n",
    "            decoder_attention_mask=y.attention_mask,\n",
    "            return_dict=True\n",
    "        ).loss\n",
    "        \n",
    "        perp.append(torch.exp(loss).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_perp = np.mean(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "perp1 = np.mean(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "perp2 = np.mean(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.27582\n",
      "22.591455\n",
      "22.662134\n"
     ]
    }
   ],
   "source": [
    "print(def_perp)\n",
    "print(perp1)\n",
    "print(perp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Привет)\n",
      "Как дела?<eom>Привет как тебя зовут?\n",
      "Отлично, а у тебя?<eom>Назар,а тебя?\n",
      "У меня все хорошо, спасибо<eom>Кистина<eom>Чем занимаешься по жизни ?<eom>Я кино актриса по жизни :)\n",
      "А ты?\n",
      "Ещё люблю путешествия<eom>Сейчас работаю на почте. Скоро поеду кататься на горных лыжах\n",
      "Я тоже люблю путешествовать. Но больше в Москву. Мечтаю там жить<eom>Ездила в прошлом году в Альпы с мужем он тоже актёр по этому редко вместе отдыхаем и там лазили по горам\n",
      "Альпинизм короче.\n",
      "О круто я из Москвы<eom>Пришла идея снять видео для своего блога в горах)<eom>Круто молодец<eom>Он о косметике, как раз проверить стойкость на своей девушке<eom>Хаха правильно\n",
      "Но осторожнее не навредит ей :)<eom>Постараюсь) а ты одинока или с кем то живёшь?<eom>А ещё я люблю рыбу мм и мм так бы и ела и ела :)\n",
      "Я с мужем он у меня тоже киноактёр<eom>Классно<eom>Любишь альпинизм?<eom>А я женат на ипотеке)))до гроба прям\n",
      "Обожаю экстрим<eom>:))))\n",
      "Это классно<eom>Ладно, извини, мне пора бежать\n",
      "-----------------------------------\n",
      "\"Привет)\n",
      "Как дела?<eom>Привет как тебя зовут?\n",
      "Отлично, а у тебя?<eom>Назар,а тебя?\n",
      "У меня все хорошо, спасибо<eom>Кистина<eom>Чем занимаешься по жизни ?<eom>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Чем занимаешься?', 0.5057803392410278),\n",
       " ('У тебя есть домашние животные?', 0.4923243522644043),\n",
       " ('У тебя есть семья?', 0.448405385017395)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = chats['dialogue'].sample().values[0]\n",
    "print(text)\n",
    "print('-----------------------------------')\n",
    "text = '<eom>'.join(t for t in text.split('<eom>')[:5]) + '<eom>'\n",
    "print(text)\n",
    "model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Чем занимаешься?', 0.6190121173858643),\n",
       " ('Что делаешь?', 0.49533969163894653),\n",
       " ('Сколько тебе лет?', 0.4428713023662567)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Привет. Как ты?<eom>Привет, не очень(<eom>\n",
    "\"\"\"\n",
    "model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5144])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(hypotheses.sequences_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoder_input_ids': tensor([[  259, 10883,   271,  5430,  6438,  6347, 16536,   291,  2709,   265,\n",
       "            773,   669,  7472,  6106,  1008,  1323,  2839,  6584,  5476,   388,\n",
       "           5416,  5892,   261,  5930,  1428,  1035, 14238,  7429,   309,   260,\n",
       "            864,   259,  7262,  6225,  1092,  6282,   374, 15640,   374,  4177,\n",
       "            893,   259,  5344,  7716,  5361,   259,  7330,  7384,  5144, 10366,\n",
       "            748,   259,   777,   315,  6557, 11651,   271,  2709,   265,   773,\n",
       "            669,  5042, 15613, 15374,   271,  8015,  6438,  5235,  6794,   291,\n",
       "           2709,   265,   773,   669,     1]]),\n",
       " 'past_key_values': None,\n",
       " 'encoder_outputs': None,\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1]]),\n",
       " 'head_mask': None,\n",
       " 'decoder_head_mask': None,\n",
       " 'cross_attn_head_mask': None,\n",
       " 'use_cache': None}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generator.prepare_inputs_for_generation(**inputs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7384c145932f83ddc52271d83a8aeef16a657eafcebab1a7065825eb89fefcc9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
