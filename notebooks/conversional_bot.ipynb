{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6cb246c4984f9389c01a351cd562cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/175 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fde23cbb3f24f558b30063924dec8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/distilrubert-tiny-cased-conversational-v1 were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"DeepPavlov/distilrubert-tiny-cased-conversational-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9897cce71a6f43e7820163d47d390503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3df72ae90564b6a87704a47290d13e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sberbank-ai/rugpt3small_based_on_gpt2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50264, 768)\n",
       "  (wpe): Embedding(2048, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModel.from_pretrained('sberbank-ai/rugpt3small_based_on_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf9e6a4fb5a4e62bf304f8733d6474e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c7660eedbc482c9fe7bbfc90a13ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('sberbank-ai/rugpt3small_based_on_gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('sberbank-ai/rugpt3small_based_on_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d83b2824c540eaa27e530ffad68a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/980k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"sberbank-ai/ruT5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"sberbank-ai/ruT5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤–µ—Ç, –≤—Å—ë —Ö–æ—Ä–æ—à–æ.\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –°–ø–æ–π–ª–µ—Ä –Ω–∞–∂–º–∏!\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 3: –ù–∞ —á—Ç–æ —Ç—ã —É—á–∏—à—å —è–∑—ã–∫?\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 4: –°–ª—É—à–∞–π\n",
      "========================================\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤–µ—Ç, –≤—Å—ë —Ö–æ—Ä–æ—à–æ.\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –í–æ—Ç —è –∏ –≤–µ—Ä–Ω—É–ª—Å—è!\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, –∞ –ß–ï–ú–£ –û–¢–ö–†–´–¢ –ê–ö–ë?\n",
      "–ü–æ–ª—å–∑\n",
      "========================================\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤–µ—Ç, –≤—Å—ë —Ö–æ—Ä–æ—à–æ.\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?\n",
      "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –£—Å—Ç—Ä–æ–∏–ª—Å—è –≤ —Å–≤–æ—é –∫–æ–Ω—Ç–æ—Ä—É (–ø–æ–º–æ–≥–∏—Ç–µ —Å –ø–æ–∏—Å–∫–æ–º –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É \"–∫–∏–Ω–¥–µ—Ä\") –í –æ–±—â–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –±–æ–ª–µ–µ\n",
      "========================================\n",
      "tensor([-0.0413, -0.0077, -0.0575])\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\n",
    "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤–µ—Ç, –≤—Å—ë —Ö–æ—Ä–æ—à–æ.\n",
    "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?\n",
    "\"\"\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    hypotheses = model.generate(\n",
    "        **inputs, \n",
    "        do_sample=True, num_return_sequences=3, num_beams=15,\n",
    "        repetition_penalty=2.5, temperature=1.9, top_k=500,\n",
    "        max_new_tokens=32, return_dict_in_generate=True, output_scores=True, early_stopping=True\n",
    "    )\n",
    "\n",
    "for t in hypotheses.sequences:\n",
    "    print(tokenizer.decode(t, skip_special_tokens=True))\n",
    "    print(\"========================================\")\n",
    "print(hypotheses.sequences_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '–•–æ—Ä–æ—à–æ.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"\"\"Us1: –ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\\n\\n\n",
    "Us2: –ü—Ä–∏–≤–µ—Ç, –≤—Å—ë —Ö–æ—Ä–æ—à–æ.\\n\\n\n",
    "Us1: –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?\\n\\n\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(\"kjafsklja\", Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-small-chitchat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–ü—Ä–∏–≤–µ—Ç, —Ç—ã –∫–∞–∫? –ó–¥–æ—Ä–æ–≤–æ. –¢–∞–∫ —Å–µ–±–µ. –ê —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?</s>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"\"\"–ü—Ä–∏–≤–µ—Ç, —Ç—ã –∫–∞–∫?\\n\\n\n",
    "–ó–¥–æ—Ä–æ–≤–æ. –¢–∞–∫ —Å–µ–±–µ.\\n\\n\n",
    "–ê —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?\\n\\n \n",
    "\"\"\"), ignore_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "class MLChitChat:\n",
    "    def __init__(self) -> None:\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-small-chitchat\")\n",
    "        self.generator = T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-small-chitchat\")\n",
    "        self.ret_seq = 5\n",
    "\n",
    "    def __call__(self, texts) -> None:\n",
    "        inputs = self.tokenizer(texts, return_tensors='pt', padding=True)\n",
    "        with torch.no_grad():\n",
    "            hypotheses = self.generator.generate(\n",
    "                **inputs, \n",
    "                do_sample=True, num_beams=3, num_return_sequences=self.ret_seq,\n",
    "                repetition_penalty=2.5, top_k=500, temperature=1.13,\n",
    "                max_length=54, output_scores=True, return_dict_in_generate=True\n",
    "            )\n",
    "\n",
    "        ans_di = {}\n",
    "        tmp_li = []\n",
    "        hypotheses = zip(hypotheses.sequences, hypotheses.sequences_scores)\n",
    "        for i, (tens, score) in enumerate(hypotheses):\n",
    "            tmp_li.append((self.tokenizer.decode(tens, skip_special_tokens=True), score.item()))\n",
    "            if (i+1) % self.ret_seq == 0:\n",
    "                ans_di.update({(i+1)//self.ret_seq:tmp_li})\n",
    "                tmp_li = []\n",
    "        return ans_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLChitChat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [('–ü—Ä–∏–≤–µ—Ç, —Å–ø–∞—Å–∏–±–æ.', -0.8036027550697327),\n",
       "  ('–ü—Ä–∏–≤–µ—Ç, —Å–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å! –ö–∞–∫ —É —Ç–µ–±—è –≤—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ?',\n",
       "   -0.40717342495918274),\n",
       "  ('–ü—Ä–∏–≤–µ—Ç, —Ç–µ–ø–µ—Ä—å –≤—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ!', -0.6237233877182007),\n",
       "  ('—Ö–æ—Ä–æ—à–æ, —É —Ç–µ–±—è —Ç–æ–∂–µ –≤—Å–µ –±—É–¥–µ—Ç –≤ –ø–æ—Ä—è–¥–∫–µ?', -0.5728853344917297)],\n",
       " 2: [('–ú–Ω–µ —Ç–∞–∫ –∂–∞–ª—å —ç—Ç–æ —Å–ª—ã—à–∞—Ç—å.', -0.39720630645751953),\n",
       "  ('–ß—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?', -0.5411677360534668),\n",
       "  ('–ù–∏—á–µ–≥–æ, –Ω–∏—á–µ–≥–æ.', -0.4679516553878784),\n",
       "  ('–û, –Ω–∏—á–µ–≥–æ –Ω–µ —Å–ª—É—á–∏–ª–æ—Å—å.', -0.4578409790992737)],\n",
       " 3: [('–ß—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?', -0.4788780212402344),\n",
       "  ('–ó–¥–æ—Ä–æ–≤–æ, —è —Ä–∞–¥ —Ç–µ–±—è –≤–∏–¥–µ—Ç—å.', -0.5614637732505798),\n",
       "  ('–ß—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?', -0.4788780212402344),\n",
       "  ('–ß—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?', -0.4788780212402344)]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\"\"\"–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\\n\\n\n",
    "–ü—Ä–∏–≤–µ—Ç, –≤—Å—ë —Ö–æ—Ä–æ—à–æ)\\n\\n\n",
    "\"\"\",\n",
    "\"\"\"–ü—Ä–∏–≤–µ—Ç, —Ç—ã –∫–∞–∫?\\n\\n\n",
    "–ó–¥–æ—Ä–æ–≤–æ. –¢–∞–∫ —Å–µ–±–µ.\\n\\n\n",
    "–ê —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?\\n\\n \n",
    "\"\"\",\n",
    "\"\"\"–ü—Ä–∏–≤–µ—Ç, —Ç—ã –∫–∞–∫? ))\\n\\n\n",
    "–ó–¥–æ—Ä–æ–≤–æ. –¢–∞–∫ —Å–µ–±–µ (\\n\\n\n",
    "–ê —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å :(\\n\\n \n",
    "\"\"\"]\n",
    "model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [('–ü—ã—Ç–∞—é—Å—å –∫–æ–µ-—á—Ç–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å.', -0.513427197933197),\n",
       "  ('–ü–æ—Ö–æ–∂–µ, —è –∑–∞–Ω–∏–º–∞—é—Å—å —Å–ø–æ—Ä—Ç–æ–º.', -0.4895842373371124),\n",
       "  ('–Ø –Ω–∏—á–µ–º –Ω–µ –∑–∞–Ω–∏–º–∞—é—Å—å.', -0.31862208247184753),\n",
       "  ('–†–∞–±–æ—Ç–∞—é.', -0.4969412684440613),\n",
       "  ('–í—Å–µ–≥–æ –ª–∏—à—å –Ω–∞ —Ä–∞–±–æ—Ç–µ. –î–æ–ª–∂–Ω–æ –±—ã—Ç—å, —Ç–µ–±–µ –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å.',\n",
       "   -0.44850507378578186)]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\\n\\n\n",
    "–ü—Ä–∏–≤–µ—Ç, –≤—Å—ë —Ö–æ—Ä–æ—à–æ.\\n\\n\n",
    "–ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?\\n\\n \n",
    "\"\"\"\n",
    "model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona_1_profile</th>\n",
       "      <th>persona_2_profile</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;span class=participant_1&gt;–£ –º–µ–Ω—è –ª—é–±–∏–º–∞—è —Ä–∞–±–æ—Ç...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–ò—â—É –ø—Ä–∏–Ω—Ü–∞.&lt;br /&gt;–í–µ–¥...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;span class=participant_1&gt;–Ø —Ä–∞–±–æ—Ç–∞—é —É—á–∏—Ç–µ–ª–µ–º&lt;b...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–Ø –±–∏–∑–Ω–µ—Å–º–µ–Ω&lt;br /&gt;–£ –º...</td>\n",
       "      <td>&lt;span class=participant_1&gt;–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;span class=participant_1&gt;–Ø –∫—É–ø–∏–ª–∞ –¥–æ–º&lt;br /&gt;–Ø ...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–Ø –ø–æ—é –≤ –∫–∞—Ä–∞–æ–∫–µ&lt;br /...</td>\n",
       "      <td>&lt;span class=participant_1&gt;–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;span class=participant_1&gt;—è –≤—Ä–∞—á –∏ –∂–µ–Ω–∞—Ç&lt;br /&gt;...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–Ø –º–∞–ª—å—á–∏–∫&lt;br /&gt;–Ø —É—á—É...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ó–¥—Ä–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;span class=participant_1&gt;–Ø —à–∫–æ–ª—å–Ω–∏—Ü–∞.&lt;br /&gt;–Ø ...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–Ø –ø—Ä–æ—Å—Ç–æ–≤–∞—Ç.&lt;br /&gt;–õ—é...</td>\n",
       "      <td>&lt;span class=participant_1&gt;–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>&lt;span class=participant_1&gt;–£ –º–µ–Ω—è 6 —Å–æ–±–∞–∫.&lt;br /...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–Ø –º—É–∑—ã–∫–∞–Ω—Ç.&lt;br /&gt;–õ—é–±...</td>\n",
       "      <td>\"&lt;span class=participant_1&gt;–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>&lt;span class=participant_1&gt;–Ø –≤–µ—Ä–Ω–∞—è.&lt;br /&gt;–ú–Ω–µ –Ω...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–Ø –ª—é–±–ª—é —Ä–æ–∫&lt;br /&gt;–ü–∏—à...</td>\n",
       "      <td>&lt;span class=participant_1&gt;–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>&lt;span class=participant_1&gt;–Ø —Å—Ç—É–¥–µ–Ω—Ç.&lt;br /&gt;–Ø —É—á...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–î–∏—Ä–µ–∫—Ç–æ—Ä —Ç—É—Ä—Ñ–∏—Ä–º—ã.&lt;b...</td>\n",
       "      <td>&lt;span class=participant_1&gt;–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>&lt;span class=participant_1&gt;–ú–æ—è –º–∞–º–∞ –∂–∏–≤–µ—Ç —Å–æ –º–Ω...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–Ø –≤–æ—Å–ø–∏—Ç–∞—Ç–µ–ª—å&lt;br /&gt;–ª...</td>\n",
       "      <td>&lt;span class=participant_1&gt;–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>&lt;span class=participant_1&gt;–Ø –∂–µ–Ω–∞—Ç.&lt;br /&gt;–õ—é–±–ª—é ...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–Ø –ª—é–±–ª—é —á–∏—Ç–∞—Ç—å&lt;br /&gt;...</td>\n",
       "      <td>&lt;span class=participant_2&gt;–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10013 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       persona_1_profile  \\\n",
       "0      <span class=participant_1>–£ –º–µ–Ω—è –ª—é–±–∏–º–∞—è —Ä–∞–±–æ—Ç...   \n",
       "1      <span class=participant_1>–Ø —Ä–∞–±–æ—Ç–∞—é —É—á–∏—Ç–µ–ª–µ–º<b...   \n",
       "2      <span class=participant_1>–Ø –∫—É–ø–∏–ª–∞ –¥–æ–º<br />–Ø ...   \n",
       "3      <span class=participant_1>—è –≤—Ä–∞—á –∏ –∂–µ–Ω–∞—Ç<br />...   \n",
       "4      <span class=participant_1>–Ø —à–∫–æ–ª—å–Ω–∏—Ü–∞.<br />–Ø ...   \n",
       "...                                                  ...   \n",
       "10008  <span class=participant_1>–£ –º–µ–Ω—è 6 —Å–æ–±–∞–∫.<br /...   \n",
       "10009  <span class=participant_1>–Ø –≤–µ—Ä–Ω–∞—è.<br />–ú–Ω–µ –Ω...   \n",
       "10010  <span class=participant_1>–Ø —Å—Ç—É–¥–µ–Ω—Ç.<br />–Ø —É—á...   \n",
       "10011  <span class=participant_1>–ú–æ—è –º–∞–º–∞ –∂–∏–≤–µ—Ç —Å–æ –º–Ω...   \n",
       "10012  <span class=participant_1>–Ø –∂–µ–Ω–∞—Ç.<br />–õ—é–±–ª—é ...   \n",
       "\n",
       "                                       persona_2_profile  \\\n",
       "0      <span class=participant_2>–ò—â—É –ø—Ä–∏–Ω—Ü–∞.<br />–í–µ–¥...   \n",
       "1      <span class=participant_2>–Ø –±–∏–∑–Ω–µ—Å–º–µ–Ω<br />–£ –º...   \n",
       "2      <span class=participant_2>–Ø –ø–æ—é –≤ –∫–∞—Ä–∞–æ–∫–µ<br /...   \n",
       "3      <span class=participant_2>–Ø –º–∞–ª—å—á–∏–∫<br />–Ø —É—á—É...   \n",
       "4      <span class=participant_2>–Ø –ø—Ä–æ—Å—Ç–æ–≤–∞—Ç.<br />–õ—é...   \n",
       "...                                                  ...   \n",
       "10008  <span class=participant_2>–Ø –º—É–∑—ã–∫–∞–Ω—Ç.<br />–õ—é–±...   \n",
       "10009  <span class=participant_2>–Ø –ª—é–±–ª—é —Ä–æ–∫<br />–ü–∏—à...   \n",
       "10010  <span class=participant_2>–î–∏—Ä–µ–∫—Ç–æ—Ä —Ç—É—Ä—Ñ–∏—Ä–º—ã.<b...   \n",
       "10011  <span class=participant_2>–Ø –≤–æ—Å–ø–∏—Ç–∞—Ç–µ–ª—å<br />–ª...   \n",
       "10012  <span class=participant_2>–Ø –ª—é–±–ª—é —á–∏—Ç–∞—Ç—å<br />...   \n",
       "\n",
       "                                                dialogue  \n",
       "0      <span class=participant_2>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤...  \n",
       "1      <span class=participant_1>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...  \n",
       "2      <span class=participant_1>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...  \n",
       "3      <span class=participant_2>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ó–¥—Ä–∞...  \n",
       "4      <span class=participant_1>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...  \n",
       "...                                                  ...  \n",
       "10008  \"<span class=participant_1>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏...  \n",
       "10009  <span class=participant_1>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...  \n",
       "10010  <span class=participant_1>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...  \n",
       "10011  <span class=participant_1>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤...  \n",
       "10012  <span class=participant_2>–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤...  \n",
       "\n",
       "[10013 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chats = pd.read_csv(\"TlkPersonaChatRus/dialogues.tsv\", sep='\\t')\n",
    "chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤–µ—Ç) —Ä–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ\\n\\n–ü–æ–ª...\n",
       "1        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç!\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏...\n",
       "2        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ö–∞–∫ ...\n",
       "3        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2...\n",
       "4        –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç!\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏...\n",
       "                               ...                        \n",
       "10008    \"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏...\n",
       "10009    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç)\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ö–∞–∫...\n",
       "10010    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ø—Ä–∏–≤...\n",
       "10011    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü—Ä–∏–≤–µ—Ç–∏–∫)\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü...\n",
       "10012    –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤–µ—Ç! —Ä–∞–¥–∞ –Ω–æ–≤–æ–º—É –∑–Ω–∞–∫–æ–º—Å—Ç–≤—É...\n",
       "Name: dialogue, Length: 10013, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats['dialogue'] = chats['dialogue'].str.replace(\"</span><br />\", \"\\n\\n\")\n",
    "chats['dialogue'] = chats['dialogue'].str.replace(\"<span class=participant_2>\", \"\")\n",
    "chats['dialogue'] = chats['dialogue'].str.replace(\"<span class=participant_1>\", \"\")\n",
    "chats['dialogue'] = chats['dialogue'].str.replace(\"<br />\", \"\")\n",
    "chats['dialogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAATfklEQVR4nO3df6zddX3H8edbqkKoUhB307TM4uxc0EaEG2DxRy6yQUFn2aYEQ7S4Ls0STDTronXG4RQS3PyxmThNNxqrUStTCQ24YVe5M/6BQLVSfoi9YhltahtprVaQ7ep7f5zP7U7rvT3n0NNzznef5yM5ud/v+/s557zP57av873f8z3nRGYiSarDs4bdgCRpcAx9SaqIoS9JFTH0Jakihr4kVWTesBs4ljPPPDOXLFlyeP0Xv/gFp5566vAa6kITegT77Kcm9AjN6LMJPcLo97l169afZOYLZ92YmSN7Of/887PdXXfdlaOuCT1m2mc/NaHHzGb02YQeM0e/T+C+nCNXPbwjSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVGemPYTheS9beMfD7XLNsmomB36skdcc9fUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SapIV6EfETsjYntEbIuI+0rtjIjYHBE7ys/TSz0i4hMRMRUR90fEeW23s7KM3xERK0/MQ5IkzaWXPf2LM/PczBwv62uBLZm5FNhS1gEuB5aWy2rgU9B6kgCuBy4ELgCun3mikCQNxvEc3lkBbCjLG4Ar2+qfzZa7gQURsRC4DNicmfsz8wCwGVh+HPcvSepRt6GfwNcjYmtErC61sczcU5Z/DIyV5UXA423X3VVqc9UlSQMyr8txr87M3RHxW8DmiPh++8bMzIjIfjRUnlRWA4yNjTE5OXl426FDh45Y72TNsul+tNSTsVPoqcdh6XUuh6UJfTahR2hGn03oEZrT52y6Cv3M3F1+7ouIW2kdk98bEQszc085fLOvDN8NnNV29cWlthuYOKo+Oct9rQPWAYyPj+fExP9dZXJykvb1Tq5de0fXY/tlzbJpruqhx2HpdS6HpQl9NqFHaEafTegRmtPnbDoe3omIUyPieTPLwKXAA8AmYOYMnJXAbWV5E/C2chbPRcDBchjoTuDSiDi9vIB7aalJkgakmz39MeDWiJgZ/4XM/PeIuBe4JSJWAY8BV5XxXwOuAKaAJ4G3A2Tm/oj4EHBvGffBzNzft0ciSeqoY+hn5qPAK2apPwFcMks9gevmuK31wPre25Qk9YPvyJWkihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFug79iDgpIr4bEbeX9bMj4tsRMRURX4qI55T6c8v6VNm+pO023lvqj0TEZX1/NJKkY+plT/+dwMNt6x8GPp6ZLwEOAKtKfRVwoNQ/XsYREecAVwMvA5YD/xQRJx1f+5KkXnQV+hGxGHg98C9lPYDXAV8uQzYAV5blFWWdsv2SMn4FsDEzn87MHwFTwAV9eAySpC51u6f/D8C7gV+X9RcAP83M6bK+C1hUlhcBjwOU7QfL+MP1Wa4jSRqAeZ0GRMQbgH2ZuTUiJk50QxGxGlgNMDY2xuTk5OFthw4dOmK9kzXLpjsP6rOxU+ipx2HpdS6HpQl9NqFHaEafTegRmtPnbDqGPvAq4I0RcQVwMvB84B+BBRExr+zNLwZ2l/G7gbOAXRExDzgNeKKtPqP9Oodl5jpgHcD4+HhOTEwc3jY5OUn7eifXrr2j67H9smbZNFf10OOw9DqXw9KEPpvQIzSjzyb0CM3pczYdD+9k5nszc3FmLqH1Quw3MvMa4C7gTWXYSuC2sryprFO2fyMzs9SvLmf3nA0sBe7p2yORJHXUzZ7+XN4DbIyIG4DvAjeX+s3A5yJiCthP64mCzHwwIm4BHgKmgesy81fHcf+SpB71FPqZOQlMluVHmeXsm8z8JfDmOa5/I3Bjr01KkvrDd+RKUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRV5Hg+WllzWDKEL28B2HnT64dyv5Kawz19SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klSRjqEfESdHxD0R8b2IeDAi/rbUz46Ib0fEVER8KSKeU+rPLetTZfuSttt6b6k/EhGXnbBHJUmaVTd7+k8Dr8vMVwDnAssj4iLgw8DHM/MlwAFgVRm/CjhQ6h8v44iIc4CrgZcBy4F/ioiT+vhYJEkddAz9bDlUVp9dLgm8DvhyqW8ArizLK8o6ZfslERGlvjEzn87MHwFTwAX9eBCSpO50dUw/Ik6KiG3APmAz8EPgp5k5XYbsAhaV5UXA4wBl+0HgBe31Wa4jSRqArr4uMTN/BZwbEQuAW4HfO1ENRcRqYDXA2NgYk5OTh7cdOnToiPVO1iyb7jyoz8ZOGc79Aj3NTa9zOSxN6LMJPUIz+mxCj9CcPmfT03fkZuZPI+Iu4PeBBRExr+zNLwZ2l2G7gbOAXRExDzgNeKKtPqP9Ou33sQ5YBzA+Pp4TExOHt01OTtK+3sm1Q/iu2jXLpvno9uF89fDOaya6HtvrXA5LE/psQo/QjD6b0CM0p8/ZdHP2zgvLHj4RcQrwh8DDwF3Am8qwlcBtZXlTWads/0ZmZqlfXc7uORtYCtzTp8chSepCN7ukC4EN5UybZwG3ZObtEfEQsDEibgC+C9xcxt8MfC4ipoD9tM7YITMfjIhbgIeAaeC6cthIkjQgHUM/M+8HXjlL/VFmOfsmM38JvHmO27oRuLH3NiVJ/eA7ciWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKtIx9CPirIi4KyIeiogHI+KdpX5GRGyOiB3l5+mlHhHxiYiYioj7I+K8tttaWcbviIiVJ+5hSZJm082e/jSwJjPPAS4CrouIc4C1wJbMXApsKesAlwNLy2U18CloPUkA1wMXAhcA1888UUiSBqNj6Gfmnsz8Tln+OfAwsAhYAWwowzYAV5blFcBns+VuYEFELAQuAzZn5v7MPABsBpb388FIko4tMrP7wRFLgG8CLwf+KzMXlHoABzJzQUTcDtyUmd8q27YA7wEmgJMz84ZSfz/wVGZ+5Kj7WE3rLwTGxsbO37hx4+Fthw4dYv78+V33u333wa7H9svYKbD3qYHfLQDLFp3W9dhe53JYmtBnE3qEZvTZhB5h9Pu8+OKLt2bm+Gzb5nV7IxExH/gK8K7M/Fkr51syMyOi+2ePY8jMdcA6gPHx8ZyYmDi8bXJykvb1Tq5de0c/WurJmmXTfHR719PaVzuvmeh6bK9zOSxN6LMJPUIz+mxCj9CcPmfT1dk7EfFsWoH/+cz8ainvLYdtKD/3lfpu4Ky2qy8utbnqkqQB6ebsnQBuBh7OzI+1bdoEzJyBsxK4ra3+tnIWz0XAwczcA9wJXBoRp5cXcC8tNUnSgHRzHOJVwFuB7RGxrdT+GrgJuCUiVgGPAVeVbV8DrgCmgCeBtwNk5v6I+BBwbxn3wczc348HIUnqTsfQLy/IxhybL5llfALXzXFb64H1vTQoSeof35ErSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0JekinQM/YhYHxH7IuKBttoZEbE5InaUn6eXekTEJyJiKiLuj4jz2q6zsozfERErT8zDkSQdSzd7+p8Blh9VWwtsycylwJayDnA5sLRcVgOfgtaTBHA9cCFwAXD9zBOFJGlwOoZ+Zn4T2H9UeQWwoSxvAK5sq382W+4GFkTEQuAyYHNm7s/MA8BmfvOJRJJ0gkVmdh4UsQS4PTNfXtZ/mpkLynIABzJzQUTcDtyUmd8q27YA7wEmgJMz84ZSfz/wVGZ+ZJb7Wk3rrwTGxsbO37hx4+Fthw4dYv78+V0/uO27D3Y9tl/GToG9Tw38bgFYtui0rsf2OpfD0oQ+m9AjNKPPJvQIo9/nxRdfvDUzx2fbNu94bzwzMyI6P3N0f3vrgHUA4+PjOTExcXjb5OQk7eudXLv2jn611bU1y6b56PbjntZnZOc1E12P7XUuh6UJfTahR2hGn03oEZrT52ye6dk7e8thG8rPfaW+GzirbdziUpurLkkaoGca+puAmTNwVgK3tdXfVs7iuQg4mJl7gDuBSyPi9PIC7qWlJkkaoI7HISLii7SOyZ8ZEbtonYVzE3BLRKwCHgOuKsO/BlwBTAFPAm8HyMz9EfEh4N4y7oOZefSLw5KkE6xj6GfmW+bYdMksYxO4bo7bWQ+s76k7SVJf+Y5cSaqIoS9JFTH0Jakihr4kVcTQl6SKDOetozohlvTwDuQ1y6b7+o7lnTe9vm+3JenEcU9fkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1Jqojfkau+6OX7eXvR6bt8/W5eqTfu6UtSRQx9SarIwEM/IpZHxCMRMRURawd9/5JUs4GGfkScBHwSuBw4B3hLRJwzyB4kqWaDfiH3AmAqMx8FiIiNwArgoQH3of8nTtQLyL3o9GJzv/nitY5HZObg7iziTcDyzPzzsv5W4MLMfEfbmNXA6rL6UuCRtps4E/jJgNp9pprQI9hnPzWhR2hGn03oEUa/zxdl5gtn2zByp2xm5jpg3WzbIuK+zBwfcEs9aUKPYJ/91IQeoRl9NqFHaE6fsxn0C7m7gbPa1heXmiRpAAYd+vcCSyPi7Ih4DnA1sGnAPUhStQZ6eCczpyPiHcCdwEnA+sx8sIebmPWwz4hpQo9gn/3UhB6hGX02oUdoTp+/YaAv5EqShst35EpSRQx9SapII0J/VD+6ISLOioi7IuKhiHgwIt5Z6h+IiN0Rsa1crhiBXndGxPbSz32ldkZEbI6IHeXn6UPs76Vt87UtIn4WEe8ahbmMiPURsS8iHmirzTp30fKJ8m/1/og4b4g9/n1EfL/0cWtELCj1JRHxVNucfnoQPR6jzzl/xxHx3jKXj0TEZUPu80ttPe6MiG2lPrT5fEYyc6QvtF7w/SHwYuA5wPeAc4bdV+ltIXBeWX4e8ANaHy/xAeCvht3fUb3uBM48qvZ3wNqyvBb48LD7bPud/xh40SjMJfBa4DzggU5zB1wB/BsQwEXAt4fY46XAvLL84bYel7SPG4G5nPV3XP4vfQ94LnB2yYGThtXnUds/CvzNsOfzmVyasKd/+KMbMvO/gZmPbhi6zNyTmd8pyz8HHgYWDbernqwANpTlDcCVw2vlCJcAP8zMx4bdCEBmfhPYf1R5rrlbAXw2W+4GFkTEwmH0mJlfz8zpsno3rffFDNUcczmXFcDGzHw6M38ETNHKgxPuWH1GRABXAV8cRC/91oTQXwQ83ra+ixEM1ohYArwS+HYpvaP8Wb1+mIdN2iTw9YjYWj7qAmAsM/eU5R8DY8Np7TdczZH/oUZtLmHuuRvVf69/RusvkBlnR8R3I+I/I+I1w2qqzWy/41Gdy9cAezNzR1tt1OZzTk0I/ZEXEfOBrwDvysyfAZ8Cfgc4F9hD60/BYXt1Zp5H6xNOr4uI17ZvzNbfqUM/f7e8ae+NwL+W0ijO5RFGZe7mEhHvA6aBz5fSHuC3M/OVwF8CX4iI5w+rPxrwOz7KWzhyp2TU5vOYmhD6I/3RDRHxbFqB//nM/CpAZu7NzF9l5q+Bf2ZAf5IeS2buLj/3AbfS6mnvzKGH8nPf8Do87HLgO5m5F0ZzLou55m6k/r1GxLXAG4BrypMT5XDJE2V5K61j5b87rB6P8TseqbkEiIh5wJ8AX5qpjdp8dtKE0B/Zj24ox/ZuBh7OzI+11duP4f4x8MDR1x2kiDg1Ip43s0zrBb4HaM3jyjJsJXDbcDo8whF7UaM2l23mmrtNwNvKWTwXAQfbDgMNVEQsB94NvDEzn2yrvzBa321BRLwYWAo8OoweSw9z/Y43AVdHxHMj4mxafd4z6P6O8gfA9zNz10xh1Oazo2G/ktzNhdYZET+g9Qz6vmH309bXq2n9WX8/sK1crgA+B2wv9U3AwiH3+WJaZ0F8D3hwZg6BFwBbgB3AfwBnDLnPU4EngNPaakOfS1pPQnuA/6F1XHnVXHNH66ydT5Z/q9uB8SH2OEXrmPjMv81Pl7F/Wv4dbAO+A/zRkOdyzt8x8L4yl48Alw+zz1L/DPAXR40d2nw+k4sfwyBJFWnC4R1JUp8Y+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jaki/wsAgDkv/gKaZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "chats['dialogue'].str.split('\\n\\n').apply(lambda x: len(x)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirily/guildenstern/.env/lib/python3.8/site-packages/transformers/generation_utils.py:2343: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 2s ¬± 33.5 s per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(chats['dialogue'].sample(10).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit model(chats['dialogue'].sample(50).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit model(chats['dialogue'].sample(25).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats['length'] = chats['dialogue'].str.split('\\n\\n').apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirily/guildenstern/.env/lib/python3.8/site-packages/transformers/generation_utils.py:2343: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 18s ¬± 19.2 s per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(chats.loc[chats['length'].between(25, 50), 'dialogue'].sample(15).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guildenstern.src.libs.models.simple_bot import MLChitChat\n",
    "\n",
    "model = MLChitChat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do_sample': True,\n",
       " 'num_beams': 3,\n",
       " 'num_return_sequences': 3,\n",
       " 'repetition_penalty': 2.5,\n",
       " 'top_k': 500,\n",
       " 'temperature': 1.11,\n",
       " 'max_length': 54,\n",
       " 'output_scores': True,\n",
       " 'return_dict_in_generate': True}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ü—Ä–∏–≤–µ—Ç\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –û,–ø—Ä–∏–≤–µ—Ç–∏–∫–∏!–Ø –ù–∞—Ç–∞–ª–∏—è,–∞ –∫–∞–∫ –≤–∞—Å –∑–æ–≤—É—Ç?\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–Ω–¥—Ä–µ–π, –¥–∞–≤–∞–π—Ç–µ –æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ó–Ω–∞–∫–æ–º–∏—Ç—å—Å—è\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –° —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ–º! —á–µ–º –∑–∞–Ω–∏–º–∞–µ—Ç–µ—Å—å? –º–æ–∂–µ—Ç —Ç–æ–∂–µ –ª—é–±–∏—Ç–µ—Å–ø–æ—Ä—Ç? —è –±–µ–∑ –Ω–µ–≥–æ –Ω–∏ –¥–Ω—è –Ω–µ –º–æ–≥—É! —Ç—å\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –Ø –¥–∏—Ä–µ–∫—Ç–æ—Ä –º–∞–≥–∞–∑–∏–Ω–∞, –Ω–æ –∑–Ω–∞–µ—Ç–µ —Å–ø–æ—Ä—Ç —è —Ç–æ–∂–µ –æ–±–æ–∂–∞—é, –æ—Å–æ–±–µ–Ω–Ω–æ –≤–æ–¥–Ω—ã–π\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ö—Å—Ç–∞—Ç–∏ —á–µ—Ä–µ–∑ –º–µ—Å—è—Ü —Å–æ–±–∏—Ä–∞—é—Å—å –Ω–∞ –º–æ—Ä–µ –ø–æ–µ—Ö–∞—Ç—å\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –í—ã –ª—é–±–∏—Ç–µ –ø—É—Ç–µ—à–µ—Å—Ç–≤–æ–≤–∞—Ç—å?\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ó–∞–º–µ—á–∞—Ç—å–Ω–æ –∫–∞–∫! –ü—É—Ç–µ—à–µ—Å—Ç–≤–æ–≤–∞—Ç—å –ø—Ä–æ—Å—Ç–æ –æ–±–æ–∂–∞—é! –ü–æ–∑–Ω–∞–≤–∞—Ç—å–Ω–æ–≤–æ–µ- –æ—á–µ–Ω—å —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ. –ú–æ–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å —Ä–∞–∑–≤–µ —á—Ç–æ—Å —á—Ç–µ–Ω–∏–µ–º –∫–Ω–∏–≥! –õ—é–±–∏—Ç–µ —á–∏—Ç–∞—Ç—å?\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –î–∞ –∑–Ω–∞–µ—Ç–µ –Ω–µ –æ—Å–æ–±–æ, –µ—Å–ª–∏ —á–∏—Ç–∞—Ç—å —Ç–æ —Ç–æ–ª—å–∫–æ —É—á–µ–±–Ω–∏–∫–∏, –ø–æ —Ä–∞–±–æ—Ç–µ, –∏ –µ—â—ë –ø–æ –∏—Å–ø–∞–Ω—Å–∫–æ–º—É, –≤–æ—Ç –∏–∑—É—á–∞—é –µ–≥–æ, –¥—É–º–∞—é–ø—Ä–∏–≥–æ–¥–∏—Ç—å—Å—è\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ê —É –≤–∞—Å –µ—Å—Ç—å –ª—é–±–∏–º–∞—è –∫–Ω–∏–≥–∞?\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –£—á–µ–±–Ω–∏–∫–∏ —Ç–æ–∂–µ —á–∏—Ç–∞—é,—è —É—á–∏–∏–µ–ª—å–Ω–∏—Ü–µ–π —Ä–∞–±–æ—Ç–∞—é.\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –û–≥–æ, –∫—Ä—É—Ç–æ, –∞ –∫–∞–∫–æ–π –ø—Ä–µ–¥–º–µ—Ç –≤–µ–¥—ë—Ç–µ?\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ï—Å—Ç—å, –®. –ë—Ä–æ–Ω—Ç–µ , –î–∂–µ–π–Ω –ï–π—Ä . –í—Å—è –ø—Ä–æ –º–µ–Ω—è, –º–æ–ª–æ–¥—É—é—É—á–∏—Ç–µ–ª—å–Ω–∏—Ü—É –≤ –ø–æ–∏—Å–∫–∞—Ö —Å–≤–æ–µ–≥–æ –ø—Ä–∏–Ω—Ü–∞ üòä\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –í –ø–æ–∏—Å–∫–∞—Ö? –ó–Ω–∞—á–∏—Ç –≤—ã –Ω–µ –∑–∞–º—É–∂–µ–º?\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ê–ª–≥–µ–±—Ä—É –∏ –≥–µ–æ–º–µ—Ç—Ä–∏—é.–ù–µ–æ–∂–∏–¥–∞–Ω–æ –Ω–∞–≤–µ—Ä–Ω–æ–µüòä\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –ü–æ–∫–∞ –Ω–µ—Ç,–ø—Ä–∏–Ω—Ü –µ—â–µ –Ω–µ –Ω–∞—à–µ–ª—Å—è)–∞ —É –≤–∞—Å –µ—Å—Ç—å —Å–µ–º—å—è?\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ù–µ—Ç, —è –Ω–µ –∂–µ–Ω–∞—Ç\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –í—ã –ª—é–±–∏—Ç–µ –º—É–∑—ã–∫—É?\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –î–∞, –∫–æ–Ω–µ—á–Ω–æ. –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é —Å–ª—É—à–∞—Ç—å —Ä–æ–∫. –ê –≤–∞–º –∫–∞–∫–æ–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–ª–∏–∑–∫–æ –ø–æ –¥—É—Ö—É?\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –Ø –º–µ–ª–æ–º–∞–Ω) –¥–∞–∂–µ —Å–∞–º –∏–≥—Ä–∞—é, –Ω–∞ –≥–∏—Ç–∞—Ä–µ\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ê –≤—ã –∏–≥—Ä–∞–µ—Ç–µ –∏–ª–∏ –∏–≥—Ä–∞–ª–∏ –Ω–∞ —á–µ–º –Ω–∏–±—É–¥—å?\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –í–∞—É! –Ω—É –æ—á–µ–Ω—å —è –≤–∞–º —Å–∫–∞–∂—É, –æ—á–µ–Ω—å! –¥—É–º–∞—é –Ω–∞–º –ø–æ—Ä–∞ –ø—Ä–æ—â–∞—Ç—å—Å—è, –∞—Ç–æ —è –µ—â–µ –ø—Ä–∏–¥—É–º–∞—é —Å–µ–±–µ, —á—Ç–æ –Ω–∞—à–ª–∞ —Å–≤–æ–µ–≥–æ –ø—Ä–∏–Ω—Ü–∞üòä\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2: –ê—Ö–∞—Ö —Ö–æ—Ä–æ—à–µ–≥–æ –≤–∞–º –¥–Ω—è!\\n\\n–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 1: –°–ø–∞—Å–∏–±–æ,–∏ –≤–∞–º!\\n\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = chats['dialogue'].sample(1).to_list()[0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', message='__floordiv__ is deprecated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('–ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è, —á—Ç–æ –≤—ã –Ω–∞–ø–æ–º–∏–Ω–∞–µ—Ç–µ –æ–± —ç—Ç–æ–º. –Ø –Ω–∞–¥–µ—é—Å—å, —á—Ç–æ –º–Ω–µ —É–¥–∞–ª–æ—Å—å —ç—Ç–æ –ø–æ–Ω—è—Ç—å!',\n",
       "  -0.5270249247550964),\n",
       " ('–ü—Ä–∏–≤–µ—Ç! –ù–∞–¥–µ—é—Å—å, –≤—ã —Å–º–æ–∂–µ—Ç–µ –Ω–∞–π—Ç–∏ —Å–µ–±—è –≤ —Å–≤–æ–µ–º –≤–æ–∑—Ä–∞—Å—Ç–µ. –£–¥–∞—á–∏!',\n",
       "  -0.5724456310272217),\n",
       " ('–Ø –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –±—ã–ª –Ω–∞ —Ä–∞–±–æ—Ç–µ, –∏ —Ç–∞–∫ –≤—Å–µ –±—É–¥–µ—Ç —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ! –ü–æ–∂–∞–ª—É–π—Å—Ç–∞!',\n",
       "  -0.7270546555519104)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-small-chitchat\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-small-chitchat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–•–æ—Ä–æ—à–æ. –ö–∞–∫–∏–µ —É —Ç–µ–±—è –¥–µ–ª–∞?', '–•–æ—Ä–æ—à–æ.', '–í–µ–ª–∏–∫–æ–ª–µ–ø–Ω–æ. –•–æ—Ä–æ—à–æ.']\n",
      "tensor([-0.4027, -0.4113, -0.5968])\n"
     ]
    }
   ],
   "source": [
    "text = '–ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏, –∫–∞–∫ —Ç–≤–æ–∏ –¥–µ–ª–∞?'\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    hypotheses = model.generate(\n",
    "        **inputs, \n",
    "        do_sample=True, top_k=500, num_return_sequences=3, num_beams=5,\n",
    "        top_p=0.95, repetition_penalty=2.5, temperature=1.15,\n",
    "        max_length=32, return_dict_in_generate=True, output_scores=True\n",
    "    )\n",
    "\n",
    "print(tokenizer.batch_decode(hypotheses.sequences, skip_special_tokens=True))\n",
    "print(hypotheses.sequences_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–∞, —Ä–∞–±–æ—Ç–∞—é.\n",
      "-0.9424518942832947\n",
      "–£ –º–µ–Ω—è –≤—Å–µ —Ö–æ—Ä–æ—à–æ.\n",
      "-0.7928904294967651\n",
      "–†–∞–±–æ—Ç–∞—é.\n",
      "-0.5319557785987854\n",
      "–ß—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?\n",
      "-0.5411679744720459\n",
      "–ú–Ω–µ –Ω—É–∂–Ω–æ –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å —Ç–æ–±–æ–π.\n",
      "-0.4335683286190033\n",
      "–ù–µ –∑–Ω–∞—é.\n",
      "-0.5221830606460571\n"
     ]
    }
   ],
   "source": [
    "text = [\"\"\"–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?\\n\\n\n",
    "–ü—Ä–∏–≤–µ—Ç, –≤—Å—ë —Ö–æ—Ä–æ—à–æ.\\n\\n\n",
    "–ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?\\n\\n \n",
    "\"\"\",\n",
    "\"\"\"–ü—Ä–∏–≤–µ—Ç, —Ç—ã –∫–∞–∫?\\n\\n\n",
    "–ó–¥–æ—Ä–æ–≤–æ. –¢–∞–∫ —Å–µ–±–µ.\\n\\n\n",
    "–ê —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?\\n\\n \n",
    "\"\"\"]\n",
    "inputs = tokenizer(text, return_tensors='pt', padding=True)\n",
    "with torch.no_grad():\n",
    "    hypotheses = model.generate(\n",
    "        **inputs, \n",
    "        do_sample=True, num_beams=3, num_return_sequences=3,\n",
    "        repetition_penalty=2.5, top_k=500, temperature=1.11,\n",
    "        max_length=54, output_scores=True, return_dict_in_generate=True\n",
    "    )\n",
    "hypotheses = zip(hypotheses.sequences, hypotheses.sequences_scores)\n",
    "for h, score in hypotheses:\n",
    "    print(tokenizer.decode(h, skip_special_tokens=True))\n",
    "    print(score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞? –ü—Ä–∏–≤–µ—Ç, –≤—Å—ë —Ö–æ—Ä–æ—à–æ. –ß–µ–º –∑–∞–Ω–∏–º–∞–µ—à—å—Å—è?</s>',\n",
       " '–ü—Ä–∏–≤–µ—Ç, —Ç—ã –∫–∞–∫? –ó–¥–æ—Ä–æ–≤–æ. –¢–∞–∫ —Å–µ–±–µ. –ê —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?</s> <pad>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives = pd.read_csv('adjectives.csv', sep='\\t')['bare'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11941"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12450"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = []\n",
    "with open('nouns_anim_m.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        nouns.append(line.strip().replace('\\ufeff', ''))\n",
    "\n",
    "len(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29 ms ¬± 10.4 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with open('guildenstern/.resource/nouns.txt') as f:\n",
    "    nouns = f.readlines()\n",
    "\n",
    "random.choice(nouns).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'—Å—Ç–µ–Ω–Ω–æ–π'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.choice(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–ö–æ–ª–µ–Ω—å–∫–∞'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "nicks = []\n",
    "nicks.append(random.choice(adjectives).strip() + ' ' + random.choice(nouns).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guildenstern.src.libs.models.nickname_generator import generate_nickname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–≠–ø–æ—Ö–∞–ª—å–Ω—ã–π –í–∞—Å—Ç—å—è–Ω–æ–≤\n",
      "–≠–ø–æ—Ö–∞–ª—å–Ω—ã–π –í–∞—Å—Ç—å—è–Ω–æ–≤\n"
     ]
    }
   ],
   "source": [
    "nick = generate_nickname()\n",
    "print(nick)\n",
    "while nick in []:\n",
    "    nick = generate_nickname()\n",
    "print(nick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('guildenstern/.resource/nouns.txt', 'w') as f:\n",
    "    f.write('\\n'.join([a for a in nouns]))\n",
    "\n",
    "with open('guildenstern/.resource/adjectives.txt', 'w') as f:\n",
    "    f.write('\\n'.join([a for a in adjectives]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd20dea9e92d4121aaaf6d00bc1dc060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/377 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d928003a2ed447bb8d46706686ad5458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/235k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79c51e3d3dc4d4390245b017e3ae357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/457k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7dd86346ad34e5f929f1c232aef910f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89585bb7f65a43d287b49cb3f6b428c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/957 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9cf3dd3af64b8f8a81f158ad13ac77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/45.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_checkpoint = 'cointegrated/rubert-tiny-toxicity'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2toxicity(text, aggregate=True):\n",
    "    \"\"\" Calculate toxicity of a text (if aggregate=True) or a vector of toxicity aspects (if aggregate=False)\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(model.device)\n",
    "        proba = torch.sigmoid(model(**inputs).logits).cpu().numpy()\n",
    "    if isinstance(text, str):\n",
    "        proba = proba[0]\n",
    "    if aggregate:\n",
    "        return 1 - proba.T[0] * (1 - proba.T[-1])\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93501186 0.04156357]\n"
     ]
    }
   ],
   "source": [
    "print(text2toxicity(['—è –ª—é–±–ª—é –Ω–∏–≥–µ—Ä–æ–≤', '—è –ª—é–±–ª—é –∞—Ñ—Ä–∏–∫–∞–Ω—Ü–µ–≤'], True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99914867 0.06166977 0.99970096]\n"
     ]
    }
   ],
   "source": [
    "print(text2toxicity(['—Å–æ—Å–∏ —Ö—É–π', '–æ—Ç —É–ª—ã–±–∫–∏ —Å—Ç–∞–Ω–µ—Ç –≤—Å–µ–º —Å–≤–µ—Ç–ª–µ–π', '–ø–∏–¥–æ—Ä—ã –∏–¥—É—Ç'], True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9912947  0.08314562 0.99971104]\n"
     ]
    }
   ],
   "source": [
    "print(text2toxicity(['–ª—è —Ç—ã –∫—Ä—ã—Å–∞', '–∑–∞—Ç–∫–Ω–∏—Å—å', '–ø—Ä–∏–¥—É—Ä–æ–∫'], True))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46cba23e8ff08ff3c4f743476507c4c8a48b1f37385563c99a3e275ccfef8284"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
